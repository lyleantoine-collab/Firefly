```yaml
# config.yaml â€” MISTRAL FIRST + SUPER LIGHTWEIGHT 4-BIT BONUS
models:
  # === 1. MISTRAL TINY 4-BIT (FASTEST, ~4 GB RAM, 20+ tokens/sec) ===
  - name: mistral
    model_name: openaccess-ai-collective/mistral-7b-instruct-v0.3-4bit

  # === 2. FALLBACK TO FULL POWER IF YOU WANT (uncomment to use) ===
  # - name: mistral
  #   model_name: mistralai/Mistral-7B-Instruct-v0.3

  # === YOUR EXISTING MODELS (keep them exactly as-is) ===
  - name: openai
    api_key: your_openai_api_key_here
    model: gpt-4o

  - name: grok
    api_key: your_grok_api_key_here

  - name: claude
    api_key: your_anthropic_api_key_here

  - name: jan
    model_name: llama3

  # === FUTURE LOCAL MODELS (just add wrapper + entry) ===
  # - name: llama
  #   model_name: meta-llama/Llama-3.2-3B-Instruct
